{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05 SampleTranslation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iam using the [Google Translate Api](https://cloud.google.com/translate/docs/reference/rest) to translate samples of tweets to see if everything works for languages that i don't understand. Iam using the free contingent that you get every month and hope it will be enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, this is an example text'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.SampleTranslation05.translation_01 import translate_text\n",
    "\n",
    "translate_text(text = \"Hallo, dies ist ein Beispiel Text\", source_language=\"de\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Sample Selection and Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As translation resources are very limited, only a small sample of the tweets will be translated. Choosing a sample for each week and for each language, because i will try to interpret the topics afterwards on a timebased level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "from src.SampleTranslation05.translation_01 import translate_df, create_week_from_timestamp, sample_from_weeks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample 100 Tweets per Week and Language and translate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for language in ['de','en','es','fr','it','ru','uk']:\n",
    "    df = pd.read_csv(f'/Users/robinfeldmann/TopicAnalysisRUWTweets/Data/Language_min_dedupl/{language}.csv')\n",
    "    df = df[df['tweetcreatedts'].astype(str).progress_apply(lambda x:len(x)>10)]\n",
    "    df = df[df['tweetcreatedts'].astype(str).progress_apply(lambda x: x[:10]).progress_apply(lambda x: x[0]=='2')]\n",
    "\n",
    "    df['week'] = create_week_from_timestamp(df)\n",
    "    df_sample = sample_from_weeks(df, sample_size=100)\n",
    "\n",
    "\n",
    "    # Commented because costs translation resources.\n",
    "    # df_sample['translated'] = translate_df(df_sample, language)\n",
    "    df_sample[['text','translated','tweetcreatedts','tweetid','week']].to_csv(f'/Users/robinfeldmann/TopicAnalysisRUWTweets/src/SampleTranslation05/TranslatedSamples/{language}_100.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample 100 english tweets and prepare as they would have been translated.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3652757fd4b24d2c8c974e2ef487c728",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12116412 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02e6ec0b6e90496f8a462bd2a3594f2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12116410 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c71864ace80b4903a75da5b47d19cbb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12116410 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5241c51857ff4040abc0712975280ad9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12116410 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8462655bc74c4ecdbf7540aa1b3de13f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12116410 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfBoundsDatetime",
     "evalue": "Parsing \"2932460195\" to datetime overflows, at position 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32mparsing.pyx:681\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.parsing.dateutil_parse\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOverflowError\u001b[0m: signed integer is greater than maximum",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOutOfBoundsDatetime\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/robinfeldmann/TopicAnalysisRUWTweets/05SampleTranslation.ipynb Cell 11\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/robinfeldmann/TopicAnalysisRUWTweets/05SampleTranslation.ipynb#X61sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m df \u001b[39m=\u001b[39m df[df[\u001b[39m'\u001b[39m\u001b[39mtweetcreatedts\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mastype(\u001b[39mstr\u001b[39m)\u001b[39m.\u001b[39mprogress_apply(\u001b[39mlambda\u001b[39;00m x:\u001b[39mlen\u001b[39m(x)\u001b[39m>\u001b[39m\u001b[39m10\u001b[39m)]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/robinfeldmann/TopicAnalysisRUWTweets/05SampleTranslation.ipynb#X61sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m df \u001b[39m=\u001b[39m df[df[\u001b[39m'\u001b[39m\u001b[39mtweetcreatedts\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mastype(\u001b[39mstr\u001b[39m)\u001b[39m.\u001b[39mprogress_apply(\u001b[39mlambda\u001b[39;00m x: x[:\u001b[39m10\u001b[39m])\u001b[39m.\u001b[39mprogress_apply(\u001b[39mlambda\u001b[39;00m x: x[\u001b[39m0\u001b[39m]\u001b[39m==\u001b[39m\u001b[39m'\u001b[39m\u001b[39m2\u001b[39m\u001b[39m'\u001b[39m)]\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/robinfeldmann/TopicAnalysisRUWTweets/05SampleTranslation.ipynb#X61sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mweek\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m create_week_from_timestamp(df)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/robinfeldmann/TopicAnalysisRUWTweets/05SampleTranslation.ipynb#X61sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m df_sample \u001b[39m=\u001b[39m sample_from_weeks(df, sample_size\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/robinfeldmann/TopicAnalysisRUWTweets/05SampleTranslation.ipynb#X61sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m df_sample[\u001b[39m'\u001b[39m\u001b[39mtranslated\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df_sample[\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mcopy()\n",
      "File \u001b[0;32m~/TopicAnalysisRUWTweets/src/SampleTranslation05/translation_01.py:72\u001b[0m, in \u001b[0;36mcreate_week_from_timestamp\u001b[0;34m(df, source_name)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_week_from_timestamp\u001b[39m(df: pd\u001b[39m.\u001b[39mDataFrame, source_name:\u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m MinLanguageDataSchema\u001b[39m.\u001b[39mTIMESTAMP) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m pd\u001b[39m.\u001b[39mSeries:\n\u001b[0;32m---> 72\u001b[0m     date \u001b[39m=\u001b[39m df[source_name]\u001b[39m.\u001b[39;49mastype(\u001b[39mstr\u001b[39;49m)\u001b[39m.\u001b[39;49mprogress_apply(\u001b[39mlambda\u001b[39;49;00m x: x[:\u001b[39m10\u001b[39;49m])\u001b[39m.\u001b[39;49mprogress_apply(\u001b[39mlambda\u001b[39;49;00m x: pd\u001b[39m.\u001b[39;49mto_datetime(x))\n\u001b[1;32m     73\u001b[0m     \u001b[39mreturn\u001b[39;00m date\u001b[39m.\u001b[39mprogress_apply(\u001b[39mlambda\u001b[39;00m x: \u001b[39mstr\u001b[39m(x\u001b[39m.\u001b[39myear)\u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m-\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(x\u001b[39m.\u001b[39mweek) \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mstr\u001b[39m(x\u001b[39m.\u001b[39mweek))\u001b[39m==\u001b[39m\u001b[39m2\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mstr\u001b[39m(x\u001b[39m.\u001b[39myear)\u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m-0\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(x\u001b[39m.\u001b[39mweek))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/std.py:920\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner\u001b[0;34m(df, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    917\u001b[0m \u001b[39m# Apply the provided function (in **kwargs)\u001b[39;00m\n\u001b[1;32m    918\u001b[0m \u001b[39m# on the df using our wrapper (which provides bar updating)\u001b[39;00m\n\u001b[1;32m    919\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 920\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39;49m(df, df_function)(wrapper, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    921\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    922\u001b[0m     t\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/series.py:4764\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4629\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m   4630\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4631\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4636\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   4637\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m   4638\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4639\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4640\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4755\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4756\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4757\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\n\u001b[1;32m   4758\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   4759\u001b[0m         func,\n\u001b[1;32m   4760\u001b[0m         convert_dtype\u001b[39m=\u001b[39;49mconvert_dtype,\n\u001b[1;32m   4761\u001b[0m         by_row\u001b[39m=\u001b[39;49mby_row,\n\u001b[1;32m   4762\u001b[0m         args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   4763\u001b[0m         kwargs\u001b[39m=\u001b[39;49mkwargs,\n\u001b[0;32m-> 4764\u001b[0m     )\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/apply.py:1209\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1206\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_compat()\n\u001b[1;32m   1208\u001b[0m \u001b[39m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1209\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/apply.py:1289\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1283\u001b[0m \u001b[39m# row-wise access\u001b[39;00m\n\u001b[1;32m   1284\u001b[0m \u001b[39m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1285\u001b[0m \u001b[39m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1286\u001b[0m \u001b[39m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1287\u001b[0m \u001b[39m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1288\u001b[0m action \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj\u001b[39m.\u001b[39mdtype, CategoricalDtype) \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1289\u001b[0m mapped \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_map_values(\n\u001b[1;32m   1290\u001b[0m     mapper\u001b[39m=\u001b[39;49mcurried, na_action\u001b[39m=\u001b[39;49maction, convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype\n\u001b[1;32m   1291\u001b[0m )\n\u001b[1;32m   1293\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1294\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1295\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1296\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[39mreturn\u001b[39;00m arr\u001b[39m.\u001b[39mmap(mapper, na_action\u001b[39m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[39mreturn\u001b[39;00m algorithms\u001b[39m.\u001b[39;49mmap_array(arr, mapper, na_action\u001b[39m=\u001b[39;49mna_action, convert\u001b[39m=\u001b[39;49mconvert)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/algorithms.py:1814\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1812\u001b[0m values \u001b[39m=\u001b[39m arr\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   1813\u001b[0m \u001b[39mif\u001b[39;00m na_action \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1814\u001b[0m     \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39;49mmap_infer(values, mapper, convert\u001b[39m=\u001b[39;49mconvert)\n\u001b[1;32m   1815\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1816\u001b[0m     \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1817\u001b[0m         values, mapper, mask\u001b[39m=\u001b[39misna(values)\u001b[39m.\u001b[39mview(np\u001b[39m.\u001b[39muint8), convert\u001b[39m=\u001b[39mconvert\n\u001b[1;32m   1818\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2926\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/std.py:915\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    910\u001b[0m     \u001b[39m# update tbar correctly\u001b[39;00m\n\u001b[1;32m    911\u001b[0m     \u001b[39m# it seems `pandas apply` calls `func` twice\u001b[39;00m\n\u001b[1;32m    912\u001b[0m     \u001b[39m# on the first column/row to decide whether it can\u001b[39;00m\n\u001b[1;32m    913\u001b[0m     \u001b[39m# take a fast or slow code path; so stop when t.total==t.n\u001b[39;00m\n\u001b[1;32m    914\u001b[0m     t\u001b[39m.\u001b[39mupdate(n\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m t\u001b[39m.\u001b[39mtotal \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mn \u001b[39m<\u001b[39m t\u001b[39m.\u001b[39mtotal \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m)\n\u001b[0;32m--> 915\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/TopicAnalysisRUWTweets/src/SampleTranslation05/translation_01.py:72\u001b[0m, in \u001b[0;36mcreate_week_from_timestamp.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_week_from_timestamp\u001b[39m(df: pd\u001b[39m.\u001b[39mDataFrame, source_name:\u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m MinLanguageDataSchema\u001b[39m.\u001b[39mTIMESTAMP) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m pd\u001b[39m.\u001b[39mSeries:\n\u001b[0;32m---> 72\u001b[0m     date \u001b[39m=\u001b[39m df[source_name]\u001b[39m.\u001b[39mastype(\u001b[39mstr\u001b[39m)\u001b[39m.\u001b[39mprogress_apply(\u001b[39mlambda\u001b[39;00m x: x[:\u001b[39m10\u001b[39m])\u001b[39m.\u001b[39mprogress_apply(\u001b[39mlambda\u001b[39;00m x: pd\u001b[39m.\u001b[39;49mto_datetime(x))\n\u001b[1;32m     73\u001b[0m     \u001b[39mreturn\u001b[39;00m date\u001b[39m.\u001b[39mprogress_apply(\u001b[39mlambda\u001b[39;00m x: \u001b[39mstr\u001b[39m(x\u001b[39m.\u001b[39myear)\u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m-\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(x\u001b[39m.\u001b[39mweek) \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mstr\u001b[39m(x\u001b[39m.\u001b[39mweek))\u001b[39m==\u001b[39m\u001b[39m2\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mstr\u001b[39m(x\u001b[39m.\u001b[39myear)\u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m-0\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(x\u001b[39m.\u001b[39mweek))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/tools/datetimes.py:1146\u001b[0m, in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m   1144\u001b[0m         result \u001b[39m=\u001b[39m convert_listlike(argc, \u001b[39mformat\u001b[39m)\n\u001b[1;32m   1145\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1146\u001b[0m     result \u001b[39m=\u001b[39m convert_listlike(np\u001b[39m.\u001b[39;49marray([arg]), \u001b[39mformat\u001b[39;49m)[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1147\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(arg, \u001b[39mbool\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(result, np\u001b[39m.\u001b[39mbool_):\n\u001b[1;32m   1148\u001b[0m         result \u001b[39m=\u001b[39m \u001b[39mbool\u001b[39m(result)  \u001b[39m# TODO: avoid this kludge.\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/tools/datetimes.py:490\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mformat\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mformat\u001b[39m \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmixed\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    488\u001b[0m     \u001b[39mreturn\u001b[39;00m _array_strptime_with_fallback(arg, name, utc, \u001b[39mformat\u001b[39m, exact, errors)\n\u001b[0;32m--> 490\u001b[0m result, tz_parsed \u001b[39m=\u001b[39m objects_to_datetime64ns(\n\u001b[1;32m    491\u001b[0m     arg,\n\u001b[1;32m    492\u001b[0m     dayfirst\u001b[39m=\u001b[39;49mdayfirst,\n\u001b[1;32m    493\u001b[0m     yearfirst\u001b[39m=\u001b[39;49myearfirst,\n\u001b[1;32m    494\u001b[0m     utc\u001b[39m=\u001b[39;49mutc,\n\u001b[1;32m    495\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    496\u001b[0m     allow_object\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    497\u001b[0m )\n\u001b[1;32m    499\u001b[0m \u001b[39mif\u001b[39;00m tz_parsed \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m     \u001b[39m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[1;32m    501\u001b[0m     \u001b[39m# is in UTC\u001b[39;00m\n\u001b[1;32m    502\u001b[0m     dta \u001b[39m=\u001b[39m DatetimeArray(result, dtype\u001b[39m=\u001b[39mtz_to_dtype(tz_parsed))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/arrays/datetimes.py:2346\u001b[0m, in \u001b[0;36mobjects_to_datetime64ns\u001b[0;34m(data, dayfirst, yearfirst, utc, errors, allow_object)\u001b[0m\n\u001b[1;32m   2343\u001b[0m \u001b[39m# if str-dtype, convert\u001b[39;00m\n\u001b[1;32m   2344\u001b[0m data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(data, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mobject_)\n\u001b[0;32m-> 2346\u001b[0m result, tz_parsed \u001b[39m=\u001b[39m tslib\u001b[39m.\u001b[39;49marray_to_datetime(\n\u001b[1;32m   2347\u001b[0m     data,\n\u001b[1;32m   2348\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m   2349\u001b[0m     utc\u001b[39m=\u001b[39;49mutc,\n\u001b[1;32m   2350\u001b[0m     dayfirst\u001b[39m=\u001b[39;49mdayfirst,\n\u001b[1;32m   2351\u001b[0m     yearfirst\u001b[39m=\u001b[39;49myearfirst,\n\u001b[1;32m   2352\u001b[0m )\n\u001b[1;32m   2354\u001b[0m \u001b[39mif\u001b[39;00m tz_parsed \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2355\u001b[0m     \u001b[39m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[1;32m   2356\u001b[0m     \u001b[39m#  is in UTC\u001b[39;00m\n\u001b[1;32m   2357\u001b[0m     \u001b[39m# Return i8 values to denote unix timestamps\u001b[39;00m\n\u001b[1;32m   2358\u001b[0m     \u001b[39mreturn\u001b[39;00m result\u001b[39m.\u001b[39mview(\u001b[39m\"\u001b[39m\u001b[39mi8\u001b[39m\u001b[39m\"\u001b[39m), tz_parsed\n",
      "File \u001b[0;32mtslib.pyx:403\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mtslib.pyx:552\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mtslib.pyx:517\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mconversion.pyx:546\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.conversion.convert_str_to_tsobject\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsing.pyx:331\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.parsing.parse_datetime_string\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsing.pyx:689\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.parsing.dateutil_parse\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOutOfBoundsDatetime\u001b[0m: Parsing \"2932460195\" to datetime overflows, at position 0"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/robinfeldmann/TopicAnalysisRUWTweets/Data/Language_min_dedupl/en.csv')\n",
    "df = df[df['tweetcreatedts'].astype(str).progress_apply(lambda x:len(x)>10)]\n",
    "df = df[df['tweetcreatedts'].astype(str).progress_apply(lambda x: x[:10]).progress_apply(lambda x: x[0]=='2' and x[1]=='0')]\n",
    "\n",
    "df['week'] = create_week_from_timestamp(df)\n",
    "df_sample = sample_from_weeks(df, sample_size=100)\n",
    "\n",
    "df_sample['translated'] = df_sample['text'].copy()\n",
    "df_sample[['text','translated','tweetcreatedts','tweetid','week']].to_csv(f'/Users/robinfeldmann/TopicAnalysisRUWTweets/src/SampleTranslation05/TranslatedSamples/en_100.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample[['text','translated','tweetcreatedts','tweetid','week']].to_csv(f'/Users/robinfeldmann/TopicAnalysisRUWTweets/src/SampleTranslation05/TranslatedSamples/en_100.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
