\documentclass[
    11pt,
    a4paper,
    egregdoesnotlikesansseriftitles,
    toc=chapterentrywithdots,
    oneside,openright,
    titlepage,
    parskip=half,
    headings=normal,  % reduces heading size
    listof=totoc,
    bibliography=totoc,
    index=totoc,
    captions=tableheading,  % caption below table
    chapterprefix,
    listof=flat,
    final
]{scrbook}


% details about your thesis
\newcommand{\titel}{Topic Modelling on Large Multilingual Twitter Data Set on Ukraine War}
\newcommand{\artderarbeit}{Expose Bachelorarbeit}  % {Bachelorarbeit,Masterarbeit}
\newcommand{\autor}{Robin Feldmann}
\newcommand{\studiengang}{Informatik}  % {Informatik,Wirtschaftsinformatik,Medieninformatik}
\newcommand{\matrikelnr}{3538270}
\newcommand{\erstgutachter}{Prof.\,Dr.~Kruspe}
\newcommand{\zweitgutachter}{Prof.\,Dr.~? }
\newcommand{\logo}{figures/TH-Nuernberg-RGB.png}
\newcommand{\keywords}{hot, fuzz}
 

% custom head and foot
\usepackage[automark]{scrlayer-scrpage}
\pagestyle{plain}
\ihead{\headmark}
\chead{}
\ohead{\pagemark}
\renewcommand*\chaptermarkformat{\chapappifchapterprefix{\ }% 
  \thechapter.\enskip}

\RedeclareSectionCommand[tocindent=0pt]{section}
\RedeclareSectionCommand[tocindent=0pt]{subsection}
%\RedeclareSectionCommand[tocnumwidth=70pt]{chapter}

\usepackage{scrhack}

% other packages
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern,relsize,textcomp,csquotes}
\usepackage{amsmath,amsfonts}
\usepackage[english,ngerman]{babel}  % flip for German thesis
\usepackage[final]{graphicx}
\usepackage{setspace,geometry,xcolor}
\usepackage{makeidx}
\usepackage{paralist,ifthen,todonotes}
\usepackage{url}
\usepackage{pdfpages}
\usepackage{titlesec}
% table setup
\usepackage{longtable}
\usepackage{array}
\usepackage{ragged2e}
\usepackage{lscape}
\usepackage{cite}
% pdf hyperref
\usepackage[
    bookmarks=true,
    bookmarksopen=true,
    bookmarksnumbered=true,
    bookmarksopenlevel=1,
    pdftitle={\titel},
    pdfauthor={\autor},
    pdfcreator={\autor},
    pdfsubject={\titel},
    pdfkeywords={\keywords},
    pdfpagelabels=true,
    colorlinks=true,
    linkcolor=red,
    urlcolor=magenta,
    anchorcolor=black,
    citecolor=cyan,
    filecolor=magenta,
    menucolor=red,
    plainpages=false,
    hypertexnames=true,
    linktocpage=true,
]{hyperref}

\usepackage[toc,acronym]{glossaries}

% configure your listings style
\usepackage{listings}
\lstset{
	tabsize=3,
	extendedchars=true,
	frame=single,
	showstringspaces=true,
	numbers=left,
	numberstyle=\small,
	breakautoindent=true
}

% page setup
% \setlength{\topskip}{\ht\strutbox}
\geometry{paper=a4paper,left=2.5cm,top=3.0cm,bindingoffset=.8cm}
\onehalfspacing
\frenchspacing
\clubpenalty = 10000
\widowpenalty = 10000 
\displaywidowpenalty = 10000

% some commands
\newcommand{\ua}{\mbox{u.\,a.\ }}
\newcommand{\zB}{\mbox{z.\,B.\ }}
\newcommand{\dahe}{\mbox{d.\,h.,\ }}
\newcommand{\bzw}{\mbox{bzw.\ }}
\newcommand{\bzgl}{\mbox{bzgl.\ }}
\newcommand{\eg}{\mbox{e.\,g.\ }}
\newcommand{\ie}{\mbox{i.\,e.\ }}
\newcommand{\wrt}{\mbox{w.\,r.\,t.\ }}
\newcommand{\etal}{\mbox{\emph{et.\,al.\ }}}
\titleformat{\chapter}[display]
  {\normalfont\bfseries}{}{0pt}{\Large}



% TODO remove if not needed...
\usepackage{blindtext}

% load glossary entries
\begin{document}

\setcounter{secnumdepth}{3}  % numerate subsections
\setcounter{tocdepth}{2}  % ...but don't include them in toc

\frontmatter
\pagenumbering{arabic} 
\include{cover}

% download the following form and complete it (hit save in your editor)
% https://intern.ohmportal.de/fileadmin/Gelenkte_Doks/Abt/SZS/SB/SB_0050_FO_Pruefungsrechtliche_Erklaerung_und_Erklaerung_zur_Veroeffentlichung_der_Abschlussarbeit_public.pdf
%\includepdf{SB_0050_FO_Pruefungsrechtliche_Erklaerung_und_Erklaerung_zur_Veroeffentlichung_der_Abschlussarbeit_public.pdf}\cleardoublepage


\tableofcontents


{\let\clearpage\relax \chapter{Introduction}}
The ongoing conflict between Ukraine and Russia represents a paramount challenge in the realm of external politics for both Germany and Europe. This confrontation not only tests diplomatic relations but also significantly influences the geopolitical landscape of the region, underscoring its critical importance \cite{Zeitenwende}. In the context of the Russian-Ukraine War, social media serves a dual role: it acts as a crucial medium for disseminating political opinions and information, and simultaneously, it emerges as a vital source of information relevant to military strategies and operations. \cite{SocialMediaUkraine}.
Twitter holds a position of exceptional significance in this context, underscored by its expansive user base exceeding 350 million in 2022 and 2023 \cite{TwitterUsers}. This platform has previously demonstrated its influential role in shaping discourse around major global events, notably during the Brexit referendum and the COVID-19  pandemic. Its pervasive reach and real-time information dissemination capabilities make it a critical tool for political engagement and public awareness in such high-stake scenarios \cite{ TwitterBrexit, TwitterBrexit2, TwitterCovid, SocialNetworking}.
Natural Language Processing methods are particularly effective for analyzing large datasets of tweets, where the sheer volume of data renders manual reading unfeasible. These techniques enable the extraction of structured information, opinions, and factual insights from these extensive text corpora, transforming vast digital conversations into comprehensible data.\cite{Fraunhofer}.
Especially Topic Modelling is a method that aims to find latent Topics and Structures inside text corpora and to group them in a semantic logical way \cite{TopicModelling}.
Multilangual Topic Modelling expands this technique to multi lingual text corpora.

{\let\clearpage\relax \chapter{Objective}}
This thesis aims to critically evaluate the effectiveness of contemporary multilingual topic modeling techniques in extracting meaningful insights from extensive multilingual Twitter datasets, specifically focusing on the discourse surrounding the Russian-Ukraine war. It seeks to determine whether these advanced computational methods are adept at navigating the complexities and nuances inherent in large-scale, multilingual social media data, thereby offering a robust tool for understanding the dynamics of digital communication in the context of international conflicts.

To achieve this objective, the thesis will first process and analyze a substantial multilingual Twitter dataset obtained from Kaggle, focusing on content related to the Russian-Ukraine conflict. Subsequently, it will provide a comprehensive overview of the current developments in multilingual topic modeling, highlighting the advancements and challenges in this field. Finally, the study will apply suitable multilingual topic modeling techniques to the dataset, aiming to effectively discern and interpret the patterns and themes that emerge from this complex digital discourse.

{\let\clearpage\relax \chapter{State of Research}}

Maathuis and Karkhof's study utilizes Latent Dirichlet Allocation and Non-Negative Matrix Factorization, coupled with Kullback-Leibler Divergence, to analyze a Telegram-sourced dataset on the Ukraine war, revealing key themes and patterns in digital communication.
In their initial approach, Maathuis and Karkhof analyzed the first two months of the Ukraine war using fewer than 10,000 messages, later expanding their study to cover the first six months with an extended dataset of fewer than 50,000 messages \cite{TopicModellingTelegram1,TopicModellingTelegram2}. 
Sazzed employs Latent Dirichlet Allocation and BERTopic to analyze approximately 80,000 tweets, subsequently integrating these findings with sentiment analysis for a comprehensive understanding of public discourse \cite{TopicTwitterLDABERt}. 
Nayak, JVN, and Bhagat apply Latent Dirichlet Allocation to scrutinize about 1,200 articles from news websites, focusing on the textual analysis of the Ukraine-Russian war \cite{TopicModelingconflig}.
Sufi uses Latent Dirichlet Allocation on a dataset of 40,000 tweets in 54 languages, pre-processing the data with translations to ensure a cohesive analytical approach \cite{SocialMediaanalysis}.
In her Bachelor thesis, Becker applies Latent Dirichlet Allocation to a Kaggle dataset identical to mine, comprising approximately 70 million tweets, employing a focused approach by segmenting the data into small time intervals and language-specific subsets \cite{Ivanna}.
To the best of my knowledge, there have been no studies yet that utilize multilingual topic modeling techniques on extensive multilingual social media datasets to analyze the Ukraine-Russian war.


{\let\clearpage\relax \chapter{Data Set}}
The dataset utilized in this study is publicly accessible on Kaggle, a widely recognized platform for data sharing and analysis. ''Kaggle is an online community for data science and machine learning (ML) enthusiasts. It is a top learning tool for novices and pros, with realistic practice problems to sharpen your data science skills.
Owned by Google, it is currently the worldâ€™s largest crowdsourced web platform for data scientists and ML practitioners. Thus, Kaggle gives you access to several professionals in your field that you can brainstorm, compete, and solve real-life problems with''\cite{Kaggle}.
The dataset, compiled by the user BwandoWando, for whom limited information is available \cite{bwandowando}, was specifically gathered to monitor the ongoing Ukraine-Russia conflict through filtering for Twitter hashtags.
It encompasses a total of around 70 million tweets, spanning from the first date of February 24, 2022, to the last date of June 14, 2023, covering 476 unique dates. The dataset spans 66 languages, with the most prevalent being English, German, French, Italian, Spanish, Ukrainian, and Russian, collectively accounting for approximately 86\% of all tweets. A comprehensive explorative analysis of this dataset will be a part of the thesis, delving into detailed aspects and patterns within the data.

{\let\clearpage\relax \chapter{Preprocessing}}
In the preprocessing section of the thesis, the dataset will undergo a comprehensive exploration, cleaning, and preprocessing process. This will be conducted in accordance with the methods outlined in ''Blueprints for Text Analytics Using Python,'' a seminal work in the field. Additionally, the principles and techniques from Professor Albrecht's lecture on Natural Language Processing will be integrated into these processes. This dual approach ensures a robust and thorough preparation of the dataset, laying a solid foundation for subsequent analysis \cite{Albrecht}.
To address duplicates in the dataset, particularly retweets and similar entries within specific timespans, a Min-Hash technique will be employed for deduplication. This method is especially effective in noisy data scenarios, ensuring efficient removal of duplicates and maintaining the dataset's integrity for more accurate analysis \cite{Dedupl}.
For the purpose of testing, a sample consisting of 100 tweets per language, per week, from non-English languages will be translated into English. This translation will be accomplished using the free test version of the Google Cloud Translate API. This systematic approach ensures a sample for each language and time period for testing later in the research process \cite{GoogleTranslateApi}.

{\let\clearpage\relax \chapter{Methodology}}

The topic modeling component of this research will be conducted in three distinct steps, each focusing on a specific subset of the data. For the initial case study, I will manually select 100 tweets, distributed evenly across four self-chosen topics, amounting to 25 tweets per topic. This curated dataset will serve as the basis for comparing results from various topic modeling approaches. The first method involves applying Latent Dirichlet Allocation (LDA) \cite{LDA} to the English translations of these tweets. Additionally, the BertTopic \cite{BERTopic} algorithm will be employed, incorporating different embedding models to analyze the data.
The evaluation of this case study will be methodically conducted in three stages to ensure a thorough analysis of the topic modeling outcomes. The first stage involves a subjective assessment, where the relevance and appeal of the identified topics will be evaluated from a human perspective. In the second stage, the results of the topic modeling will be compared against the topics I have pre-selected by hand. This comparison aims to measure the alignment between the machine-generated topics and the manually chosen ones. The third and final stage of evaluation employs established metrics for topic models: Coherence, measured using Normalized Pointwise Mutual Information (NPMI)\cite{npmi} and Diversity, determined by calculating the percentage of unique words per topic \cite{diversity}. These metrics provide an objective and quantitative analysis of the model's performance, ensuring a comprehensive evaluation of its effectiveness in topic identification and differentiation.
\backmatter

\cleardoublepage



\printnoidxglossaries
  \renewcommand\bibname{Literaturverzeichnis} 
\bibliography{literatur}
\bibliographystyle{unsrtdin}


\end{document}
